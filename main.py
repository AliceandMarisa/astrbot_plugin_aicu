# æ ‡å‡†åº“
import asyncio
import json
import time
import re
from collections import Counter
from datetime import datetime
from pathlib import Path

# ç¬¬ä¸‰æ–¹åº“
import jinja2
from curl_cffi.requests import AsyncSession
from playwright.async_api import async_playwright

# AstrBot
from astrbot.api.event import filter, AstrMessageEvent
from astrbot.api.star import Context, Star, register, StarTools
from astrbot.api import logger


@register("aicu_analysis", "Huahuatgc", "AICU Bç«™è¯„è®ºæŸ¥è¯¢", "2.9.5", "https://github.com/Huahuatgc/astrbot_plugin_aicu")
class AicuAnalysisPlugin(Star):
    # ================= é…ç½®å¸¸é‡ =================
    # åŸæœ‰çš„ API
    AICU_BILI_API_URL = "https://worker.aicu.cc/api/bili/space"
    AICU_MARK_API_URL = "https://api.aicu.cc/api/v3/user/getusermark"
    AICU_REPLY_API_URL = "https://api.aicu.cc/api/v3/search/getreply"

    # æ–°å¢çš„å¼¹å¹• API
    AICU_DANMAKU_API_URL = "https://api.aicu.cc/api/v3/search/getvideodm"  # è§†é¢‘å¼¹å¹•
    AICU_LIVE_DANMAKU_API_URL = "https://api.aicu.cc/api/v3/search/getlivedm"  # ç›´æ’­å¼¹å¹•
    # æ–°å¢çš„å…¥åœºä¿¡æ¯ API
    AICU_ENTRY_API_URL = "https://ukamnads.icu/api/v2/user"  # ç”¨æˆ·å…¥åœºä¿¡æ¯

    # æ–°å¢çš„ç²‰ä¸ç‰Œå’Œå¤§èˆªæµ· API
    AICU_MEDAL_API_URL = "https://workers.vrp.moe/bilibili/user-medals/{uid}"  # ç²‰ä¸ç‰Œä¿¡æ¯
    AICU_GUARD_API_URL = "https://workers.vrp.moe/bilibili/live-guards/{uid}?p=1"  # å¤§èˆªæµ·ä¿¡æ¯

    # æ–°å¢çš„AIåˆ†æAPI
    AICU_AI_ANALYSIS_URL = "https://api.aicu.cc/ai"  # AIåˆ†æè¯„è®º

    BILI_VIDEO_INFO_URL = "https://api.bilibili.com/x/web-interface/view"  # Bç«™è§†é¢‘ä¿¡æ¯API

    DEFAULT_REPLY_PAGE_SIZE = 100  # é»˜è®¤æŠ“å–è¯„è®ºæ•°
    DEFAULT_DANMAKU_PAGE_SIZE = 100  # é»˜è®¤å¼¹å¹•æŸ¥è¯¢æ•°é‡
    DEFAULT_ENTRY_PAGE_SIZE = 20  # é»˜è®¤å…¥åœºä¿¡æ¯æ¯é¡µæ•°é‡
    DEFAULT_AVATAR_URL = "https://i0.hdslb.com/bfs/face/member/noface.jpg"
    DEFAULT_AI_ANALYSIS_TIMEOUT = 30  # AIåˆ†æè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

    # è¯·æ±‚å¤´å¸¸é‡
    DEFAULT_HEADERS = {
        'User-Agent': "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36",
        'accept-language': "zh-CN,zh;q=0.9",
        'cache-control': "no-cache",
        'origin': "https://www.aicu.cc",
        'referer': "https://www.aicu.cc/",
        'pragma': "no-pragma",
        'priority': "u=1, i",
        'sec-ch-ua': "\"Chromium\";v=\"140\", \"Not=A?Brand\";v=\"24\", \"Google Chrome\";v=\"140\"",
        'sec-ch-ua-mobile': "?0",
        'sec-ch-ua-platform': "\"Windows\"",
        'sec-fetch-dest': "empty",
        'sec-fetch-mode': "cors",
        'sec-fetch-site': "same-site",
    }

    # å…¥åœºä¿¡æ¯APIçš„ç‰¹å®šè¯·æ±‚å¤´
    ENTRY_HEADERS = {
        'User-Agent': "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36",
        'accept': "*/*",
        'accept-encoding': "gzip, deflate, br, zstd",
        'accept-language': "zh-CN,zh;q=0.9",
        'origin': "https://laplace.live",
        'priority': "u=1, i",
        'referer': "https://laplace.live/",
        'sec-ch-ua': "\"Not A(Brand\";v=\"8\", \"Chromium\";v=\"132\", \"Google Chrome\";v=\"132\"",
        'sec-ch-ua-mobile': "?0",
        'sec-ch-ua-platform': "\"Windows\"",
        'sec-fetch-dest': "empty",
        'sec-fetch-mode': "cors",
        'sec-fetch-site': "cross-site",
    }

    # AIåˆ†æçš„ç‰¹å®šè¯·æ±‚å¤´
    AI_ANALYSIS_HEADERS = {
        'User-Agent': "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36",
        'accept': "*/*",
        'accept-language': "zh-CN,zh;q=0.9",
        'origin': "https://www.aicu.cc",
        'priority': "u=1, i",
        'referer': "https://www.aicu.cc/",
        'sec-ch-ua': "\"Not A(Brand\";v=\"8\", \"Chromium\";v=\"132\", \"Google Chrome\";v=\"132\"",
        'sec-ch-ua-mobile': "?0",
        'sec-ch-ua-platform': "\"Windows\"",
        'sec-fetch-dest': "empty",
        'sec-fetch-mode': "cors",
        'sec-fetch-site': "same-site",
        'content-type': "text/plain"
    }

    def __init__(self, context: Context, config: dict):
        super().__init__(context)
        self.config = config
        self._browser = None
        self._playwright = None

        # Cloudflare éªŒè¯ç›¸å…³ç¼“å­˜
        self._aicu_cf_cookie: str | None = None
        self._aicu_cf_cookie_expires_at: float = 0.0  # æ—¶é—´æˆ³ï¼Œé¿å…è¿‡äºé¢‘ç¹åˆ·æ–°

        # ä½¿ç”¨æ¡†æ¶æä¾›çš„æ ‡å‡†æ•°æ®ç›®å½•
        self.data_dir = StarTools.get_data_dir("aicu_analysis")
        self.output_dir = self.data_dir / "temp"
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # æ’ä»¶æºç ç›®å½•
        self.plugin_dir = Path(__file__).parent

    async def _get_browser(self):
        """è·å–æˆ–åˆ›å»ºæµè§ˆå™¨å®ä¾‹"""
        if self._browser is None:
            self._playwright = await async_playwright().start()
            try:
                headless = self.config.get("browser_headless", True)
                launch_options = {
                    "headless": headless,
                    "args": [
                        "--disable-blink-features=AutomationControlled",
                        "--disable-dev-shm-usage",
                        "--no-sandbox",
                        "--disable-setuid-sandbox",
                    ],
                }
                try:
                    self._browser = await self._playwright.chromium.launch(**launch_options)
                except Exception:
                    logger.warning("[AICU] æ— æ³•æ­£å¸¸å¯åŠ¨æµè§ˆå™¨ï¼Œå°è¯•ä½¿ç”¨æ— æ²™ç®±æ¨¡å¼(ç®€åŒ–å‚æ•°)")
                    self._browser = await self._playwright.chromium.launch(
                        headless=headless,
                        args=['--no-sandbox'],
                    )
            except Exception as e:
                logger.error(f"[AICU] å¯åŠ¨æµè§ˆå™¨ä¸¥é‡å¤±è´¥: {e}")
                await self._playwright.stop()
                self._playwright = None
                raise e
        return self._browser

    async def _ensure_aicu_cf_cookie(self):
        """
        ä½¿ç”¨æ— å¤´æµè§ˆå™¨è®¿é—® aicu.cc è·å– Cloudflare éªŒè¯åçš„ Cookieï¼Œ
        å¹¶ç¼“å­˜ä¸€æ®µæ—¶é—´ï¼Œä¾›åç»­æ¥å£è¯·æ±‚å¤ç”¨ã€‚

        æ³¨æ„ï¼š
        - å¦‚æœè¿ç»­å¤šæ¬¡å°è¯•ä»ç„¶æ‹¿ä¸åˆ° Cookieï¼Œä¼šè¿›å…¥å†·å´æœŸï¼Œåœ¨å†·å´æœŸå†…ä¸å†é˜»å¡è¯·æ±‚ã€‚
        """
        now = time.time()

        # 1. å·²ç»æœ‰æœ‰æ•ˆçš„ CF Cookieï¼Œç›´æ¥ç”¨
        if self._aicu_cf_cookie and now < self._aicu_cf_cookie_expires_at:
            return

        # 2. ä¸Šæ¬¡å°è¯•å¤±è´¥åå¤„äºå†·å´æœŸï¼Œä¹Ÿç›´æ¥è¿”å›ï¼Œé¿å…æ¯æ¬¡è¯·æ±‚éƒ½å¡ä½
        if (not self._aicu_cf_cookie) and now < self._aicu_cf_cookie_expires_at:
            # è¿™é‡Œ _aicu_cf_cookie_expires_at è¡¨ç¤ºâ€œä¸‹æ¬¡å†å°è¯•è¿‡ç â€çš„æ—¶é—´ç‚¹
            return

        browser = await self._get_browser()
        context = await browser.new_context(
            viewport={"width": 1280, "height": 720},
            user_agent=self.DEFAULT_HEADERS.get("User-Agent"),
        )
        page = await context.new_page()
        target_url = "https://www.aicu.cc/"
        logger.info(f"[AICU] é€šè¿‡æµè§ˆå™¨è®¿é—® {target_url} ä»¥è·å– Cloudflare éªŒè¯ Cookie")

        try:
            # åªç­‰ DOMReadyï¼Œtimeout ç¼©çŸ­åˆ° 5 ç§’
            try:
                await page.goto(target_url, wait_until="domcontentloaded", timeout=5000)
            except Exception as e:
                logger.warning(f"[AICU] æ‰“å¼€ aicu.cc æ—¶å‘ç”Ÿé”™è¯¯/è¶…æ—¶(å·²å¿½ç•¥): {e}")

            cf_cookie = None
            max_wait_seconds = 5  # æœ€å¤šé¢å¤–ç­‰ 5 ç§’è½®è¯¢ Cookie

            for i in range(max_wait_seconds):
                cookies = await context.cookies()
                cookie_kv = []
                for c in cookies:
                    domain = c.get("domain") or ""
                    if "aicu.cc" in domain:
                        cookie_kv.append(f"{c['name']}={c['value']}")

                if cookie_kv:
                    cf_cookie = "; ".join(cookie_kv)
                    logger.info(f"[AICU] å·²è·å– Cloudflare ç›¸å…³ Cookie (è€—æ—¶çº¦ {i+1} ç§’): {cf_cookie}")
                    break

                await asyncio.sleep(1)

            if cf_cookie:
                # æˆåŠŸæ‹¿åˆ° Cookieï¼šç¼“å­˜ 30 åˆ†é’Ÿï¼Œé¿å…é¢‘ç¹è¿‡ç 
                self._aicu_cf_cookie = cf_cookie
                self._aicu_cf_cookie_expires_at = time.time() + 1800  # 30 åˆ†é’Ÿåå†å°è¯•åˆ·æ–°
            else:
                logger.warning("[AICU] è½®è¯¢åä»æœªä»æµè§ˆå™¨ä¸Šä¸‹æ–‡ä¸­è·å–åˆ° aicu.cc ç›¸å…³ Cookieï¼ŒCloudflare å¯èƒ½ä»åœ¨æ‹¦æˆª")
                # å¤±è´¥ï¼šè¿›å…¥å†·å´æœŸï¼Œé¿å…æ¯æ¬¡è¯·æ±‚éƒ½é‡å¤å¡ 5 ç§’
                self._aicu_cf_cookie_expires_at = time.time() + 600  # 10 åˆ†é’Ÿåå†å°è¯•ä¸€æ¬¡

        except Exception as e:
            logger.error(f"[AICU] é€šè¿‡æµè§ˆå™¨è·å– Cloudflare Cookie å¤±è´¥: {e}", exc_info=True)
            # å‘ç”Ÿå¼‚å¸¸ä¹Ÿè®¾ç½®ä¸€ä¸ªå†·å´æœŸï¼Œé¿å…ä¸åœé‡è¯•
            self._aicu_cf_cookie_expires_at = time.time() + 600
        finally:
            try:
                await context.close()
            except Exception:
                pass

    async def _close_browser(self):
        """å…³é—­æµè§ˆå™¨å®ä¾‹"""
        if self._browser:
            await self._browser.close()
            self._browser = None

        if self._playwright:
            await self._playwright.stop()
            self._playwright = None

    async def on_plugin_load(self):
        logger.info(f"[AICU] æ’ä»¶åŠ è½½å®Œæˆï¼Œæ‰€æœ‰ç¾¤èŠå’Œç§èŠå‡å¯ä½¿ç”¨")

    async def on_plugin_unload(self):
        await self._close_browser()
        logger.info("[AICU] æ’ä»¶å¸è½½ï¼Œæµè§ˆå™¨èµ„æºå·²æ¸…ç†")

    # ================= æ–°å¢ï¼šUIDè§£æå‡½æ•° =================
    def _extract_uid(self, uid_str: str) -> str:
        """
        ä»å„ç§æ ¼å¼çš„UIDå­—ç¬¦ä¸²ä¸­æå–çº¯æ•°å­—UID

        æ”¯æŒçš„æ ¼å¼ï¼š
        - çº¯æ•°å­—ï¼š123456
        - å¸¦UIDå‰ç¼€ï¼šUID:123456
        - å¸¦uidå‰ç¼€ï¼šuid:123456
        - å¸¦UID=å‰ç¼€ï¼šUID=123456
        - å¸¦uid=å‰ç¼€ï¼šuid=123456
        - åŒ…å«å…¶ä»–å­—ç¬¦ï¼šUID:123456abcï¼ˆä¼šæå–æ•°å­—éƒ¨åˆ†ï¼‰
        """
        if not uid_str:
            return ""

        # è½¬æ¢ä¸ºå°å†™æ–¹ä¾¿å¤„ç†
        uid_lower = uid_str.lower()

        # å¦‚æœåŒ…å«uid:æˆ–uid=å‰ç¼€ï¼Œå»æ‰å‰ç¼€
        if uid_lower.startswith("uid:"):
            uid_str = uid_str[4:]  # å»æ‰"uid:"ï¼ˆ4ä¸ªå­—ç¬¦ï¼‰
        elif uid_lower.startswith("uid="):
            uid_str = uid_str[4:]  # å»æ‰"uid="ï¼ˆ4ä¸ªå­—ç¬¦ï¼‰

        # æå–æ‰€æœ‰æ•°å­—å­—ç¬¦
        digits = re.findall(r'\d+', uid_str)

        # å¦‚æœæ‰¾åˆ°æ•°å­—ï¼Œè¿”å›ç¬¬ä¸€ä¸ªè¿ç»­æ•°å­—ä¸²
        if digits:
            return digits[0]

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ•°å­—ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        return ""

    def _validate_uid(self, uid: str) -> tuple[bool, str]:
        """éªŒè¯UIDæ˜¯å¦æœ‰æ•ˆï¼Œè¿”å›(æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)"""
        if not uid:
            return False, "âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„UID"

        extracted_uid = self._extract_uid(uid)

        if not extracted_uid:
            return False, "âŒ æœªèƒ½åœ¨è¾“å…¥ä¸­æ‰¾åˆ°æœ‰æ•ˆçš„æ•°å­—UID"

        if not extracted_uid.isdigit():
            return False, "âŒ UIDå¿…é¡»ä¸ºçº¯æ•°å­—"

        # æ£€æŸ¥UIDé•¿åº¦
        if len(extracted_uid) < 1:
            return False, "âŒ UIDä¸èƒ½ä¸ºç©º"

        if len(extracted_uid) > 20:
            logger.warning(f"[AICU] æ£€æµ‹åˆ°è¶…é•¿UID ({len(extracted_uid)}ä½): {extracted_uid}")

        return True, extracted_uid

    # ================= 1. å¼‚æ­¥è¯·æ±‚å°è£… =================
    async def _make_request(self, url: str, params: dict, cookie_override: str = None, use_entry_headers: bool = False):
        """å¼‚æ­¥é€šç”¨è¯·æ±‚ï¼ˆå¯¹ aicu.cc åŸŸåè‡ªåŠ¨é€šè¿‡æµè§ˆå™¨è·å– Cloudflare Cookieï¼‰"""
        headers = self.DEFAULT_HEADERS.copy()

        if use_entry_headers:
            headers.update(self.ENTRY_HEADERS)

        # aicu.cc åŸŸåå°è¯•å…ˆè¿‡ Cloudflare
        if "aicu.cc" in url:
            try:
                await self._ensure_aicu_cf_cookie()
            except Exception as e:
                logger.warning(f"[AICU] è·å– Cloudflare Cookie å¤±è´¥ï¼Œå°†ç»§ç»­ä½¿ç”¨åŸå§‹è¯·æ±‚: {e}")

        # ç»„è£… cookieï¼šè°ƒç”¨æ–¹è¦†ç›– / ç”¨æˆ·é…ç½® + Cloudflare Cookie
        cookie_parts: list[str] = []

        if cookie_override is not None:
            if cookie_override:
                cookie_parts.append(cookie_override)
        elif self.config.get("cookie"):
            cookie_parts.append(self.config.get("cookie"))

        if self._aicu_cf_cookie:
            cookie_parts.append(self._aicu_cf_cookie)

        if cookie_parts:
            headers["cookie"] = "; ".join(cookie_parts)

        async with AsyncSession() as session:
            try:
                logger.debug(f"[AICU] Fetching: {url}")
                response = await session.get(url, params=params, headers=headers, timeout=30)

                if response.status_code != 200:
                    logger.warning(f"[AICU] è¯·æ±‚è¿”å›é200çŠ¶æ€ç : {response.status_code} | URL: {url}")
                    return None

                loop = asyncio.get_running_loop()
                return await loop.run_in_executor(None, response.json)

            except Exception as e:
                logger.error(f"[AICU] ç½‘ç»œè¯·æ±‚å¼‚å¸¸: {e}")
                return None

    async def _make_ai_analysis_request(self, comments_text: str):
        """å‘é€AIåˆ†æè¯·æ±‚"""
        headers = self.AI_ANALYSIS_HEADERS.copy()

        # AI åˆ†æä¹Ÿåœ¨ aicu.cc åŸŸåä¸‹ï¼Œéœ€è¦å…ˆå°è¯•è¿‡ Cloudflare
        try:
            await self._ensure_aicu_cf_cookie()
        except Exception as e:
            logger.warning(f"[AICU] è·å– Cloudflare Cookie å¤±è´¥ï¼ˆAIåˆ†æï¼‰ï¼Œå°†ç»§ç»­ä½¿ç”¨åŸå§‹è¯·æ±‚: {e}")

        cookie_parts: list[str] = []
        if self.config.get("cookie"):
            cookie_parts.append(self.config.get("cookie"))
        if self._aicu_cf_cookie:
            cookie_parts.append(self._aicu_cf_cookie)
        if cookie_parts:
            headers["cookie"] = "; ".join(cookie_parts)

        timeout = self.config.get("ai_analysis_timeout", self.DEFAULT_AI_ANALYSIS_TIMEOUT)

        async with AsyncSession() as session:
            try:
                logger.debug(f"[AICU] å‘é€AIåˆ†æè¯·æ±‚ï¼Œè¯„è®ºé•¿åº¦: {len(comments_text)}")
                response = await session.post(
                    self.AICU_AI_ANALYSIS_URL,
                    data=comments_text.encode('utf-8'),
                    headers=headers,
                    timeout=timeout
                )

                if response.status_code != 200:
                    logger.warning(f"[AICU] AIåˆ†æè¯·æ±‚è¿”å›é200çŠ¶æ€ç : {response.status_code}")
                    return None

                # è§£æSSEæµå¼å“åº”
                analysis_result = ""
                content = response.text

                # æŒ‰è¡Œåˆ†å‰²å“åº”å†…å®¹
                lines = content.strip().split('\n')
                for line in lines:
                    line = line.strip()
                    if not line:
                        continue

                    # æ£€æŸ¥æ˜¯å¦æ˜¯SSEæ ¼å¼
                    if line.startswith('data: '):
                        data_content = line[6:]  # å»æ‰"data: "å‰ç¼€

                        # æ£€æŸ¥æ˜¯å¦ç»“æŸ
                        if data_content == '[DONE]':
                            break

                        try:
                            # è§£æJSON
                            json_data = json.loads(data_content)
                            if 'response' in json_data:
                                analysis_result += json_data['response']
                        except json.JSONDecodeError:
                            # å¦‚æœä¸æ˜¯æœ‰æ•ˆçš„JSONï¼Œå¯èƒ½ç›´æ¥æ˜¯æ–‡æœ¬
                            if data_content and data_content != 'null':
                                analysis_result += data_content
                    else:
                        # å¦‚æœä¸æ˜¯SSEæ ¼å¼ï¼Œç›´æ¥æ·»åŠ åˆ°ç»“æœ
                        analysis_result += line

                return analysis_result.strip()

            except Exception as e:
                logger.error(f"[AICU] AIåˆ†æè¯·æ±‚å¼‚å¸¸: {e}")
                return None

    async def _get_bili_video_info(self, aid: str = None, bvid: str = None):
        """è·å–Bç«™è§†é¢‘ä¿¡æ¯"""
        if not aid and not bvid:
            return None

        params = {}
        if bvid:
            params['bvid'] = bvid
        elif aid:
            params['aid'] = aid

        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Referer': 'https://www.bilibili.com'
        }

        async with AsyncSession() as session:
            try:
                response = await session.get(self.BILI_VIDEO_INFO_URL, params=params, headers=headers, timeout=10)
                if response.status_code == 200:
                    data = response.json()
                    if data.get('code') == 0:
                        return data.get('data', {})
            except Exception as e:
                logger.warning(f"[AICU] è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
        return None

    # ================= 2. åŸæœ‰è¯„è®ºæŸ¥è¯¢åŠŸèƒ½ =================
    async def _fetch_all_data(self, uid: str, page_size: int):
        """å¹¶å‘è·å–æ‰€æœ‰ç”¨æˆ·æ•°æ®"""
        task_bili = self._make_request(self.AICU_BILI_API_URL, {'mid': uid})
        task_mark = self._make_request(self.AICU_MARK_API_URL, {'uid': uid})

        reply_data = await self._make_request(
            self.AICU_REPLY_API_URL,
            {'uid': uid, 'pn': "1", 'ps': str(page_size), 'mode': "0", 'keyword': ""}
        )

        if not reply_data or not reply_data.get('data'):
            logger.info("[AICU] è¯„è®ºè·å–å¤±è´¥ï¼Œå°è¯•ä¸å¸¦ Cookie é‡è¯•...")
            reply_data = await self._make_request(
                self.AICU_REPLY_API_URL,
                {'uid': uid, 'pn': "1", 'ps': str(page_size), 'mode': "0", 'keyword': ""},
                cookie_override=""
            )

        bili_data, mark_data = await asyncio.gather(task_bili, task_mark)
        return bili_data, mark_data, reply_data

    def _parse_profile(self, bili_raw, uid):
        profile = {
            "name": f"UID:{uid}", "avatar": self.DEFAULT_AVATAR_URL,
            "sign": "", "level": 0, "vip_label": "", "fans": 0, "following": 0
        }

        if not bili_raw or bili_raw.get('code') != 0:
            return profile

        data = bili_raw.get('data', {})
        card = data.get('card', {})

        if card:
            profile["name"] = card.get('name', uid)
            profile["avatar"] = card.get('face', profile["avatar"])
            profile["sign"] = card.get('sign', "")
            profile["fans"] = card.get('fans', 0)
            profile["following"] = card.get('friend', 0)
            profile["level"] = card.get('level_info', {}).get('current_level', 0)
            vip = card.get('vip', {})
            if vip.get('label', {}).get('text'):
                profile["vip_label"] = vip.get('label', {}).get('text')

        return profile

    def _parse_device(self, mark_raw):
        device_name = "æœªçŸ¥è®¾å¤‡"
        history_names = []  # ç¡®ä¿é»˜è®¤æ˜¯ç©ºåˆ—è¡¨

        try:
            if mark_raw and mark_raw.get('code') == 0:
                m_data = mark_raw.get('data', {})
                if not isinstance(m_data, dict):
                    m_data = {}

                devices = m_data.get('device', [])
                if devices and isinstance(devices, list) and len(devices) > 0:
                    device_name = devices[0].get('name') or devices[0].get('type') or "æœªçŸ¥è®¾å¤‡"

                history_names = m_data.get('hname', [])
                # ç¡®ä¿ history_names æ˜¯åˆ—è¡¨
                if not isinstance(history_names, list):
                    history_names = []

            elif not self.config.get("cookie"):
                device_name = "éœ€é…ç½®Cookie"
        except Exception as e:
            logger.warning(f"[AICU] è§£æè®¾å¤‡ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            history_names = []  # å‡ºé”™æ—¶è¿”å›ç©ºåˆ—è¡¨

        return device_name, history_names

    def _parse_replies(self, reply_raw):
        """è§£æè¯„è®ºåˆ—è¡¨"""
        replies = []
        if reply_raw and reply_raw.get('code') == 0:
            data_block = reply_raw.get('data', {})
            if 'replies' not in data_block and isinstance(data_block.get('data'), dict):
                data_block = data_block['data']
            replies = data_block.get('replies', []) or []

        # ç¡®ä¿ replies æ˜¯åˆ—è¡¨
        if not isinstance(replies, list):
            replies = []

        formatted_replies = []
        hours = []
        lengths = []

        for i, r in enumerate(replies):
            ts = r.get('time', 0)
            dt = datetime.fromtimestamp(ts)
            msg = r.get('message', '')
            hours.append(dt.strftime("%H"))
            lengths.append(len(msg))
            formatted_replies.append({
                "index": i + 1,
                "message": msg,
                "readable_time": dt.strftime('%Y-%m-%d %H:%M'),
                "rank": r.get('rank', 0),
                "timestamp": ts
            })

        hour_counts = Counter(hours)
        most_common_hour = hour_counts.most_common(1)
        active_hour = most_common_hour[0][0] if most_common_hour else "N/A"
        avg_len = round(sum(lengths) / len(lengths), 1) if lengths else 0

        return {
            "list": formatted_replies,
            "count": len(formatted_replies),
            "stats": {
                "active_hour": active_hour,
                "avg_length": avg_len
            }
        }

    async def _generate_ai_analysis(self, replies):
        """ç”ŸæˆAIåˆ†æ"""
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨AIåˆ†æ
        if not self.config.get("enable_ai_analysis", False):
            return None

        try:
            # é™åˆ¶åˆ†æçš„æœ€å¤§è¯„è®ºæ•°é‡
            max_comments = self.config.get("max_ai_comments", 20)
            analysis_replies = replies[:max_comments]

            # æ„å»ºåˆ†ææ–‡æœ¬
            analysis_text = f"è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·çš„è¯„è®ºå†…å®¹ï¼Œæ€»ç»“è¯„è®ºç‰¹ç‚¹å’Œå‘è¨€é£æ ¼ï¼š\n\n"
            for i, reply in enumerate(analysis_replies):
                analysis_text += f"è¯„è®º{i+1} ({reply['readable_time']}): {reply['message']}\n"

            # æ·»åŠ åˆ†æè¦æ±‚
            analysis_text += "\nè¯·åˆ†æï¼š\n1. è¯„è®ºå†…å®¹ä¸»é¢˜å’Œæƒ…æ„Ÿå€¾å‘\n2. å‘è¨€è€…çš„å…´è¶£åå¥½\n3. è¯­è¨€é£æ ¼å’Œè¡¨è¾¾ç‰¹ç‚¹\n4. å¯èƒ½çš„å¹´é¾„ç¾¤ä½“æˆ–èº«ä»½ç‰¹å¾\n5. æ€»ä½“è¯„ä»·"

            # è°ƒç”¨AIåˆ†æAPI
            analysis_result = await self._make_ai_analysis_request(analysis_text)

            return analysis_result

        except Exception as e:
            logger.error(f"[AICU] AIåˆ†æç”Ÿæˆå¤±è´¥: {e}")
            return None

    # ================= 3. æ–°å¢å¼¹å¹•æŸ¥è¯¢åŠŸèƒ½ =================
    async def _fetch_danmaku_data(self, uid: str, page_size: int):
        """è·å–ç”¨æˆ·å¼¹å¹•æ•°æ®"""
        return await self._make_request(
            self.AICU_DANMAKU_API_URL,
            {'uid': uid, 'pn': "1", 'ps': str(page_size), 'keyword': ""}
        )

    def _parse_danmaku(self, danmaku_raw, enable_video_info: bool = True):
        """è§£æå¼¹å¹•æ•°æ®"""
        danmaku_list = []
        if danmaku_raw and danmaku_raw.get('code') == 0:
            data = danmaku_raw.get('data', {})
            cursor = data.get('cursor', {})
            total_count = cursor.get('all_count', 0)
            items = data.get('videodmlist', [])

            # ç»Ÿè®¡ä¿¡æ¯
            hours = []
            lengths = []
            video_ids = []

            for i, item in enumerate(items):
                ts = item.get('ctime', 0)
                dt = datetime.fromtimestamp(ts)
                content = item.get('content', '')
                oid = item.get('oid', '')  # è§†é¢‘aid
                progress = item.get('progress', 0)  # å¼¹å¹•æ—¶é—´ç‚¹(æ¯«ç§’)

                # è½¬æ¢ä¸ºåˆ†:ç§’æ ¼å¼
                seconds = progress // 1000
                minutes = seconds // 60
                remaining_seconds = seconds % 60
                time_point = f"{minutes}:{remaining_seconds:02d}"

                hours.append(dt.strftime("%H"))
                lengths.append(len(content))
                video_ids.append(oid)

                danmaku_list.append({
                    "index": i + 1,
                    "content": content,
                    "readable_time": dt.strftime('%Y-%m-%d %H:%M'),
                    "video_id": oid,
                    "time_point": time_point,
                    "timestamp": ts,
                    "progress": progress
                })

            # ç»Ÿè®¡æ´»è·ƒæ—¶æ®µ
            hour_counts = Counter(hours)
            most_common_hour = hour_counts.most_common(1)
            active_hour = most_common_hour[0][0] if most_common_hour else "N/A"

            # ç»Ÿè®¡æœ€æ´»è·ƒçš„è§†é¢‘
            video_counts = Counter(video_ids)
            most_active_video = video_counts.most_common(1)[0][0] if video_counts else None

            avg_length = round(sum(lengths) / len(lengths), 1) if lengths else 0

            return {
                "list": danmaku_list,
                "total_count": total_count,
                "fetched_count": len(danmaku_list),
                "stats": {
                    "active_hour": active_hour,
                    "avg_length": avg_length,
                    "most_active_video": most_active_video,
                    "video_count": len(set(video_ids))
                }
            }

        return {
            "list": [],
            "total_count": 0,
            "fetched_count": 0,
            "stats": {
                "active_hour": "N/A",
                "avg_length": 0,
                "most_active_video": None,
                "video_count": 0
            }
        }

    # ================= 4. æ–°å¢ç›´æ’­å¼¹å¹•æŸ¥è¯¢åŠŸèƒ½ =================
    async def _fetch_live_danmaku_data(self, uid: str, page_size: int):
        """è·å–ç”¨æˆ·ç›´æ’­å¼¹å¹•æ•°æ®"""
        return await self._make_request(
            self.AICU_LIVE_DANMAKU_API_URL,
            {'uid': uid, 'pn': "1", 'ps': str(page_size), 'keyword': ""}
        )

    def _parse_live_danmaku(self, live_danmaku_raw):
        """è§£æç›´æ’­å¼¹å¹•æ•°æ®"""
        live_list = []
        if live_danmaku_raw and live_danmaku_raw.get('code') == 0:
            data = live_danmaku_raw.get('data', {})
            cursor = data.get('cursor', {})
            total_count = cursor.get('all_count', 0)
            items = data.get('list', [])

            # ç»Ÿè®¡ä¿¡æ¯
            hours = []
            lengths = []
            room_ids = []
            anchors = []
            all_danmaku = []  # æ”¶é›†æ‰€æœ‰å¼¹å¹•ç”¨äºå±•ç¤º

            for room_info in items:
                room_data = room_info.get('roominfo', {})
                danmaku_items = room_info.get('danmu', [])

                room_id = room_data.get('roomid', '')
                room_name = room_data.get('roomname', '')
                anchor_name = room_data.get('upname', '')
                anchor_uid = room_data.get('upuid', '')

                room_ids.append(room_id)
                anchors.append(anchor_name)

                for i, danmaku in enumerate(danmaku_items):
                    ts = danmaku.get('ts', 0)
                    dt = datetime.fromtimestamp(ts)
                    content = danmaku.get('text', '')
                    username = danmaku.get('uname', '')

                    hours.append(dt.strftime("%H"))
                    lengths.append(len(content))

                    all_danmaku.append({
                        "index": len(all_danmaku) + 1,
                        "content": content,
                        "readable_time": dt.strftime('%Y-%m-%d %H:%M'),
                        "room_id": room_id,
                        "room_name": room_name[:30] + "..." if len(room_name) > 30 else room_name,
                        "anchor_name": anchor_name[:15] + "..." if len(anchor_name) > 15 else anchor_name,
                        "username": username,
                        "timestamp": ts
                    })

            # é™åˆ¶å±•ç¤ºæ•°é‡
            display_danmaku = all_danmaku[:50]  # æœ€å¤šæ˜¾ç¤º50æ¡

            # ç»Ÿè®¡ä¿¡æ¯
            hour_counts = Counter(hours)
            most_common_hour = hour_counts.most_common(1)
            active_hour = most_common_hour[0][0] if most_common_hour else "N/A"

            room_counts = Counter(room_ids)
            most_active_room = room_counts.most_common(1)[0][0] if room_counts else None

            anchor_counts = Counter(anchors)
            most_active_anchor = anchor_counts.most_common(1)[0][0] if anchor_counts else None

            avg_length = round(sum(lengths) / len(lengths), 1) if lengths else 0

            return {
                "list": display_danmaku,
                "total_count": total_count,
                "fetched_count": len(all_danmaku),
                "stats": {
                    "active_hour": active_hour,
                    "avg_length": avg_length,
                    "most_active_room": most_active_room,
                    "most_active_anchor": most_active_anchor,
                    "room_count": len(set(room_ids)),
                    "anchor_count": len(set(anchors))
                }
            }

        return {
            "list": [],
            "total_count": 0,
            "fetched_count": 0,
            "stats": {
                "active_hour": "N/A",
                "avg_length": 0,
                "most_active_room": None,
                "most_active_anchor": None,
                "room_count": 0,
                "anchor_count": 0
            }
        }

    # ================= 5. æ–°å¢å…¥åœºä¿¡æ¯æŸ¥è¯¢åŠŸèƒ½ =================
    async def _fetch_entry_data(self, uid: str, page_num: int = 0, page_size: int = None):
        """è·å–ç”¨æˆ·å…¥åœºä¿¡æ¯æ•°æ®"""
        if page_size is None:
            page_size = self.DEFAULT_ENTRY_PAGE_SIZE

        return await self._make_request(
            self.AICU_ENTRY_API_URL,
            {
                'uid': uid,
                'pageSize': str(page_size),
                'pageNum': str(page_num),
                'target': ''
            },
            use_entry_headers=True
        )

    async def _fetch_medal_data(self, uid: str):
        """è·å–ç”¨æˆ·ç²‰ä¸ç‰Œæ•°æ®"""
        url = self.AICU_MEDAL_API_URL.format(uid=uid)
        return await self._make_request(url, {}, use_entry_headers=True)

    async def _fetch_guard_data(self, uid: str):
        """è·å–ç”¨æˆ·å¤§èˆªæµ·æ•°æ®"""
        url = self.AICU_GUARD_API_URL.format(uid=uid)
        return await self._make_request(url, {}, use_entry_headers=True)

    def _parse_medal_data(self, medal_raw):
        """è§£æç²‰ä¸ç‰Œæ•°æ®"""
        medals = []
        if medal_raw and medal_raw.get('code') == 0:
            data = medal_raw.get('data', {})
            medal_list = data.get('list', [])

            for medal in medal_list:
                medal_info = medal.get('medal_info', {})
                target_name = medal.get('target_name', '')

                # è§£æé¢œè‰²å€¼
                color_start = medal_info.get('medal_color_start', 0)
                color_end = medal_info.get('medal_color_end', 0)
                color_border = medal_info.get('medal_color_border', 0)

                # è½¬æ¢é¢œè‰²å€¼ä¸ºåå…­è¿›åˆ¶
                def int_to_hex(color_int):
                    if color_int <= 0:
                        return "#cccccc"
                    return f"#{color_int:06x}"

                medals.append({
                    "name": medal_info.get('medal_name', ''),
                    "level": medal_info.get('level', 0),
                    "target_name": target_name,
                    "color_start": int_to_hex(color_start),
                    "color_end": int_to_hex(color_end),
                    "color_border": int_to_hex(color_border),
                    "is_wearing": medal_info.get('wearing_status', 0) == 1,
                    "guard_level": medal_info.get('guard_level', 0),
                    "intimacy": medal_info.get('intimacy', 0),
                    "next_intimacy": medal_info.get('next_intimacy', 0),
                    "today_feed": medal_info.get('today_feed', 0),
                    "day_limit": medal_info.get('day_limit', 0)
                })

        return medals

    def _parse_guard_data(self, guard_raw):
        """è§£æå¤§èˆªæµ·æ•°æ®"""
        guards = []
        if guard_raw and guard_raw.get('code') == 0:
            data = guard_raw.get('data', {})

            # å¤„ç† top3 åˆ—è¡¨
            top3_list = data.get('top3', [])
            guard_list = data.get('list', [])

            # åˆå¹¶ top3 å’Œ list
            all_guards = top3_list + guard_list

            for guard in all_guards:
                medal_info = guard.get('medal_info', {})
                guard_level = guard.get('guard_level', 0)

                # è·³è¿‡æœªå¼€é€šå¤§èˆªæµ·çš„é¡¹
                if guard_level == 0:
                    continue

                # è·å–èˆ°é•¿ç­‰çº§åç§°
                guard_name_map = {
                    1: "æ€»ç£",
                    2: "æç£",
                    3: "èˆ°é•¿"
                }
                guard_name = guard_name_map.get(guard_level, "èˆ°é•¿")

                # è§£æç²‰ä¸ç‰Œé¢œè‰²
                color_start = medal_info.get('medal_color_start', 0)
                color_end = medal_info.get('medal_color_end', 0)
                color_border = medal_info.get('medal_color_border', 0)

                def int_to_hex(color_int):
                    if color_int <= 0:
                        return "#cccccc"
                    return f"#{color_int:06x}"

                guards.append({
                    "anchor_name": guard.get('username', ''),
                    "guard_name": guard_name,
                    "guard_level": guard_level,
                    "medal_name": medal_info.get('medal_name', ''),
                    "medal_level": medal_info.get('medal_level', 0),
                    "color_start": int_to_hex(color_start),
                    "color_end": int_to_hex(color_end),
                    "color_border": int_to_hex(color_border),
                    "accompany_days": guard.get('accompany', 0),
                    "rank": guard.get('rank', 0)
                })

        # æŒ‰èˆ°é•¿ç­‰çº§æ’åºï¼ˆæ€»ç£>æç£>èˆ°é•¿ï¼‰
        guards.sort(key=lambda x: x['guard_level'])

        return guards

    def _parse_entry(self, entry_raw):
        """è§£æå…¥åœºä¿¡æ¯æ•°æ®"""
        if not entry_raw or entry_raw.get('code') != 200:
            return {
                "list": [],
                "total": 0,
                "has_more": False,
                "page_num": 0,
                "page_size": 0,
                "stats": {
                    "room_count": 0,
                    "anchor_count": 0,
                    "total_duration": 0,
                    "avg_duration": 0
                }
            }

        data = entry_raw.get('data', {})
        total = data.get('total', 0)
        page_num = data.get('pageNum', 0)
        page_size = data.get('pageSize', 0)
        has_more = data.get('hasMore', False)

        records = data.get('data', {}).get('records', [])

        formatted_entries = []
        room_ids = []
        anchor_names = []
        durations = []
        live_titles = []

        for i, record in enumerate(records):
            channel = record.get('channel', {})
            live = record.get('live', {})
            danmakus = record.get('danmakus', [])

            # æå–ä¸»æ’­ä¿¡æ¯
            anchor_name = channel.get('uName', 'æœªçŸ¥ä¸»æ’­')
            anchor_avatar = channel.get('faceUrl', self.DEFAULT_AVATAR_URL)
            room_id = channel.get('roomId', '')
            room_title = channel.get('title', '')

            # ä¸»æ’­æ ‡ç­¾
            tags = channel.get('tags', [])
            if not isinstance(tags, list):
                tags = []
            tags = tags[:3]  # åªå–å‰3ä¸ªæ ‡ç­¾

            # æå–ç›´æ’­ä¿¡æ¯
            live_title = live.get('title', '')
            parent_area = live.get('parentArea', '')
            area = live.get('area', '')

            # ç›´æ’­é—´ç»Ÿè®¡æ•°æ®
            watch_count = live.get('watchCount', 0)
            like_count = live.get('likeCount', 0)
            total_income = live.get('totalIncome', 0)
            danmakus_count = live.get('danmakusCount', 0)

            # ä¸»æ’­æ€»æ•°æ®
            channel_total_danmaku = channel.get('totalDanmakuCount', 0)
            channel_total_income = channel.get('totalIncome', 0)
            channel_total_live = channel.get('totalLiveCount', 0)

            start_date = live.get('startDate', 0)
            stop_date = live.get('stopDate', 0)

            # è®¡ç®—ç›´æ’­æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
            duration_minutes = 0
            if start_date > 0 and stop_date > 0:
                duration_seconds = (stop_date - start_date) // 1000
                duration_minutes = duration_seconds // 60

            # æå–å…¥åœºæ—¶é—´ï¼ˆå–ç¬¬ä¸€ä¸ªå¼¹å¹•æ—¶é—´ï¼‰
            entry_time = 0
            if danmakus and len(danmakus) > 0:
                entry_time = danmakus[0].get('sendDate', 0)

            # è½¬æ¢ä¸ºå¯è¯»æ—¶é—´
            if entry_time > 0:
                entry_dt = datetime.fromtimestamp(entry_time / 1000)
                readable_entry_time = entry_dt.strftime('%Y/%m/%d %H:%M:%S')
                readable_date = entry_dt.strftime('%Y/%m/%d')
                readable_weekday = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥'][entry_dt.weekday()]
            else:
                readable_entry_time = "æœªçŸ¥æ—¶é—´"
                readable_date = "æœªçŸ¥æ—¥æœŸ"
                readable_weekday = "æœªçŸ¥"

            # è®¡ç®—è§‚çœ‹æ—¶é•¿
            watch_duration = "N/A"
            if entry_time > 0 and stop_date > 0:
                watch_seconds = (stop_date - entry_time) // 1000
                if watch_seconds > 0:
                    watch_hours = watch_seconds // 3600
                    watch_minutes = (watch_seconds % 3600) // 60
                    watch_duration = f"{watch_hours}h {watch_minutes}m"

            # æ”¶å…¥ä¿¡æ¯æ ¼å¼åŒ–
            income_str = f"Â¥{total_income:.1f}" if total_income > 0 else "Â¥0"
            channel_income_str = f"Â¥{channel_total_income:.0f}" if channel_total_income > 0 else "Â¥0"

            # è§‚çœ‹äººæ•°æ ¼å¼åŒ–
            if watch_count >= 10000:
                watch_count_str = f"{watch_count/10000:.1f}w"
            else:
                watch_count_str = str(watch_count)

            # ç‚¹èµæ•°æ ¼å¼åŒ–
            if like_count >= 10000:
                like_count_str = f"{like_count/10000:.1f}w"
            elif like_count >= 1000:
                like_count_str = f"{like_count/1000:.1f}k"
            else:
                like_count_str = str(like_count)

            # å¼¹å¹•æ•°æ ¼å¼åŒ–
            if danmakus_count >= 10000:
                danmakus_count_str = f"{danmakus_count/10000:.1f}w"
            elif danmakus_count >= 1000:
                danmakus_count_str = f"{danmakus_count/1000:.1f}k"
            else:
                danmakus_count_str = str(danmakus_count)

            # ä¸»æ’­æ€»å¼¹å¹•æ•°æ ¼å¼åŒ–
            if channel_total_danmaku >= 10000:
                channel_total_danmaku_str = f"{channel_total_danmaku/10000:.1f}w"
            elif channel_total_danmaku >= 1000:
                channel_total_danmaku_str = f"{channel_total_danmaku/1000:.1f}k"
            else:
                channel_total_danmaku_str = str(channel_total_danmaku)

            room_ids.append(room_id)
            anchor_names.append(anchor_name)
            durations.append(duration_minutes)
            live_titles.append(live_title)

            formatted_entries.append({
                "index": i + 1,
                "anchor_name": anchor_name,
                "anchor_avatar": anchor_avatar,
                "room_id": room_id,
                "room_title": room_title[:50] + "..." if len(room_title) > 50 else room_title,
                "live_title": live_title[:60] + "..." if len(live_title) > 60 else live_title,
                "readable_date": readable_date,
                "readable_weekday": readable_weekday,
                "readable_entry_time": readable_entry_time,
                "entry_timestamp": entry_time,
                "watch_duration": watch_duration,
                "duration_minutes": duration_minutes,
                "parent_area": parent_area,
                "area": area,
                "tags": tags,
                "total_income": income_str,
                "channel_total_income": channel_income_str,
                "danmakus_count": danmakus_count_str,
                "channel_total_danmaku": channel_total_danmaku_str,
                "watch_count": watch_count_str,
                "like_count": like_count_str,
                "channel_total_live": channel_total_live,
                "is_living": channel.get('isLiving', False)
            })

        # ç»Ÿè®¡ä¿¡æ¯
        room_count = len(set(room_ids))
        anchor_count = len(set(anchor_names))
        total_duration = sum(durations)
        avg_duration = round(total_duration / len(durations), 1) if durations else 0

        # ç»Ÿè®¡æœ€å¸¸è§‚çœ‹çš„ä¸»æ’­
        anchor_counts = Counter(anchor_names)
        most_active_anchor = anchor_counts.most_common(1)[0][0] if anchor_counts else "N/A"

        return {
            "list": formatted_entries,
            "total": total,
            "has_more": has_more,
            "page_num": page_num,
            "page_size": page_size,
            "stats": {
                "room_count": room_count,
                "anchor_count": anchor_count,
                "total_duration": total_duration,
                "avg_duration": avg_duration,
                "most_active_anchor": most_active_anchor
            }
        }

    # ================= 6. å›¾ç‰‡æ¸²æŸ“ =================
    async def _render_image(self, render_data, template_name: str = "template.html"):
        """æ¸²æŸ“å›¾ç‰‡"""
        template_path = self.plugin_dir / template_name
        if not template_path.exists():
            raise FileNotFoundError(f"æ‰¾ä¸åˆ° {template_name} æ–‡ä»¶")

        with open(template_path, "r", encoding="utf-8") as f:
            template_str = f.read()

        template = jinja2.Template(template_str)
        html_content = template.render(**render_data)

        file_name = f"aicu_{render_data['uid']}_{int(time.time())}.png"
        file_path = self.output_dir / file_name

        try:
            browser = await self._get_browser()
            # å…¥åœºä¿¡æ¯éœ€è¦æ›´å¤§çš„é«˜åº¦
            if template_name == "template_entry.html":
                viewport = {'width': 750, 'height': 2000}
            else:
                viewport = {'width': 600, 'height': 1000}  # å¢åŠ é«˜åº¦ä»¥é€‚åº”AIåˆ†æ

            # è·å–è¶…æ—¶é…ç½®
            timeout = self.config.get("browser_timeout", 30) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’

            page = await browser.new_page(viewport=viewport, device_scale_factor=2)

            try:
                await page.set_content(html_content, wait_until='networkidle', timeout=timeout)
                try:
                    await page.locator(".container").screenshot(path=str(file_path))
                except Exception as e:
                    logger.warning(f"å±€éƒ¨æˆªå›¾å¤±è´¥ï¼Œå°è¯•å…¨é¡µæˆªå›¾: {e}")
                    await page.screenshot(path=str(file_path), full_page=True)
            finally:
                await page.close()
        except Exception as e:
            logger.error(f"æ¸²æŸ“è¿‡ç¨‹å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
            raise e

        return str(file_path)

    # ================= 7. æŒ‡ä»¤å…¥å£ =================
    @filter.command("uid")
    async def analyze_uid(self, event: AstrMessageEvent, uid: str):
        """æŸ¥è¯¢ AICU ç”¨æˆ·ç”»åƒ - æ”¯æŒå¤šç§UIDæ ¼å¼"""
        # éªŒè¯å¹¶æå–UID
        valid, result = self._validate_uid(uid)
        if not valid:
            yield event.plain_result(result)
            return

        # result ç°åœ¨æ˜¯æå–åçš„çº¯æ•°å­—UID
        extracted_uid = result

        yield event.plain_result(f"ğŸ” æ­£åœ¨è·å– UID: {extracted_uid} çš„è¯„è®ºæ•°æ®...")

        try:
            # ä½¿ç”¨ max_reply_count é…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
            page_size = self.config.get("max_reply_count", self.DEFAULT_REPLY_PAGE_SIZE)
            bili_raw, mark_raw, reply_raw = await self._fetch_all_data(extracted_uid, page_size)

            if not bili_raw and not reply_raw:
                yield event.plain_result(f"âŒ æ•°æ®è·å–å¤±è´¥ã€‚è¯·æ£€æŸ¥é…ç½®ä¸­çš„ Cookie æ˜¯å¦æ­£ç¡®ã€‚")
                return

            profile = self._parse_profile(bili_raw, extracted_uid)
            device_name, history_names = self._parse_device(mark_raw)

            # ç¡®ä¿ history_names æ˜¯åˆ—è¡¨ä¸”å¯åˆ‡ç‰‡
            if not history_names:
                history_names = []
            elif not isinstance(history_names, list):
                history_names = []

            reply_data = self._parse_replies(reply_raw)

            # ç”ŸæˆAIåˆ†æ
            ai_analysis = None
            if self.config.get("enable_ai_analysis", False) and reply_data["list"]:
                ai_analysis = await self._generate_ai_analysis(reply_data["list"])

            render_data = {
                "uid": extracted_uid,
                "profile": profile,
                "device_name": device_name,
                "history_names": history_names[:10],
                "total_count": reply_data["count"],
                "avg_length": reply_data["stats"]["avg_length"],
                "active_hour": reply_data["stats"]["active_hour"],
                "replies": reply_data["list"],
                "ai_analysis": ai_analysis,
                "enable_ai_analysis": self.config.get("enable_ai_analysis", False),
                "generate_time": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }

            img_path = await self._render_image(render_data)
            yield event.image_result(img_path)

        except Exception as e:
            logger.error(f"æ’ä»¶å¤„ç†å¤±è´¥: {e}", exc_info=True)
            yield event.plain_result(f"âŒ æ’ä»¶è¿è¡Œé”™è¯¯ï¼Œè¯·æŸ¥çœ‹åå°æ—¥å¿—ã€‚")

    @filter.command("å¼¹å¹•")
    async def analyze_danmaku(self, event: AstrMessageEvent, uid: str):
        """æŸ¥è¯¢ç”¨æˆ·å¼¹å¹•è®°å½• - æ”¯æŒå¤šç§UIDæ ¼å¼"""
        # éªŒè¯å¹¶æå–UID
        valid, result = self._validate_uid(uid)
        if not valid:
            yield event.plain_result(result)
            return

        # result ç°åœ¨æ˜¯æå–åçš„çº¯æ•°å­—UID
        extracted_uid = result

        # ä½¿ç”¨ max_danmaku_count é…ç½®
        page_size = self.config.get("max_danmaku_count", self.DEFAULT_DANMAKU_PAGE_SIZE)
        # ä½¿ç”¨ enable_video_info é…ç½®
        enable_video_info = self.config.get("enable_video_info", True)

        yield event.plain_result(f"ğŸ” æ­£åœ¨æŸ¥è¯¢ UID: {extracted_uid} çš„å¼¹å¹•è®°å½•...")

        try:
            danmaku_raw = await self._fetch_danmaku_data(extracted_uid, page_size)

            if not danmaku_raw:
                yield event.plain_result(f"âŒ å¼¹å¹•æ•°æ®è·å–å¤±è´¥ã€‚è¯·æ£€æŸ¥é…ç½®ä¸­çš„ Cookie æ˜¯å¦æ­£ç¡®ã€‚")
                return

            danmaku_data = self._parse_danmaku(danmaku_raw, enable_video_info)

            if danmaku_data["total_count"] == 0:
                yield event.plain_result(f"ğŸ” æœªæ‰¾åˆ° UID: {extracted_uid} çš„å¼¹å¹•è®°å½•")
                return

            # è·å–ç”¨æˆ·åŸºæœ¬ä¿¡æ¯
            bili_raw, mark_raw, _ = await asyncio.gather(
                self._make_request(self.AICU_BILI_API_URL, {'mid': extracted_uid}),
                self._make_request(self.AICU_MARK_API_URL, {'uid': extracted_uid}),
                asyncio.sleep(0)
            )

            profile = self._parse_profile(bili_raw, extracted_uid)
            device_name, history_names = self._parse_device(mark_raw)

            # ç¡®ä¿ history_names æ˜¯åˆ—è¡¨ä¸”å¯åˆ‡ç‰‡
            if not history_names:
                history_names = []
            elif not isinstance(history_names, list):
                history_names = []

            render_data = {
                "uid": extracted_uid,
                "profile": profile,
                "device_name": device_name,
                "history_names": history_names[:5],
                "danmaku_list": danmaku_data["list"],
                "total_count": danmaku_data["total_count"],
                "fetched_count": danmaku_data["fetched_count"],
                "avg_length": danmaku_data["stats"]["avg_length"],
                "active_hour": danmaku_data["stats"]["active_hour"],
                "video_count": danmaku_data["stats"]["video_count"],
                "most_active_video": danmaku_data["stats"]["most_active_video"],
                "generate_time": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                "search_type": "å¼¹å¹•"
            }

            # ä½¿ç”¨å¼¹å¹•ä¸“ç”¨æ¨¡æ¿
            img_path = await self._render_image(render_data, "template_danmaku.html")
            yield event.image_result(img_path)

        except Exception as e:
            logger.error(f"å¼¹å¹•æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
            yield event.plain_result(f"âŒ å¼¹å¹•æŸ¥è¯¢é”™è¯¯ï¼Œè¯·æŸ¥çœ‹åå°æ—¥å¿—ã€‚")

    @filter.command("ç›´æ’­å¼¹å¹•")
    async def analyze_live_danmaku(self, event: AstrMessageEvent, uid: str):
        """æŸ¥è¯¢ç”¨æˆ·ç›´æ’­å¼¹å¹•è®°å½• - æ”¯æŒå¤šç§UIDæ ¼å¼"""
        # éªŒè¯å¹¶æå–UID
        valid, result = self._validate_uid(uid)
        if not valid:
            yield event.plain_result(result)
            return

        # result ç°åœ¨æ˜¯æå–åçš„çº¯æ•°å­—UID
        extracted_uid = result

        # ä½¿ç”¨ max_danmaku_count é…ç½®
        page_size = self.config.get("max_danmaku_count", self.DEFAULT_DANMAKU_PAGE_SIZE)

        yield event.plain_result(f"ğŸ” æ­£åœ¨æŸ¥è¯¢ UID: {extracted_uid} çš„ç›´æ’­å¼¹å¹•è®°å½•...")

        try:
            live_danmaku_raw = await self._fetch_live_danmaku_data(extracted_uid, page_size)

            if not live_danmaku_raw:
                yield event.plain_result(f"âŒ ç›´æ’­å¼¹å¹•æ•°æ®è·å–å¤±è´¥ã€‚è¯·æ£€æŸ¥é…ç½®ä¸­çš„ Cookie æ˜¯å¦æ­£ç¡®ã€‚")
                return

            live_data = self._parse_live_danmaku(live_danmaku_raw)

            if live_data["total_count"] == 0:
                yield event.plain_result(f"ğŸ” æœªæ‰¾åˆ° UID: {extracted_uid} çš„ç›´æ’­å¼¹å¹•è®°å½•")
                return

            # è·å–ç”¨æˆ·åŸºæœ¬ä¿¡æ¯
            bili_raw, mark_raw, _ = await asyncio.gather(
                self._make_request(self.AICU_BILI_API_URL, {'mid': extracted_uid}),
                self._make_request(self.AICU_MARK_API_URL, {'uid': extracted_uid}),
                asyncio.sleep(0)
            )

            profile = self._parse_profile(bili_raw, extracted_uid)
            device_name, history_names = self._parse_device(mark_raw)

            # ç¡®ä¿ history_names æ˜¯åˆ—è¡¨ä¸”å¯åˆ‡ç‰‡
            if not history_names:
                history_names = []
            elif not isinstance(history_names, list):
                history_names = []

            render_data = {
                "uid": extracted_uid,
                "profile": profile,
                "device_name": device_name,
                "history_names": history_names[:5],
                "live_list": live_data["list"],
                "total_count": live_data["total_count"],
                "fetched_count": live_data["fetched_count"],
                "avg_length": live_data["stats"]["avg_length"],
                "active_hour": live_data["stats"]["active_hour"],
                "room_count": live_data["stats"]["room_count"],
                "anchor_count": live_data["stats"]["anchor_count"],
                "most_active_room": live_data["stats"]["most_active_room"],
                "most_active_anchor": live_data["stats"]["most_active_anchor"],
                "generate_time": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                "search_type": "ç›´æ’­å¼¹å¹•"
            }

            # ä½¿ç”¨ç›´æ’­å¼¹å¹•ä¸“ç”¨æ¨¡æ¿
            img_path = await self._render_image(render_data, "template_live.html")
            yield event.image_result(img_path)

        except Exception as e:
            logger.error(f"ç›´æ’­å¼¹å¹•æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
            yield event.plain_result(f"âŒ ç›´æ’­å¼¹å¹•æŸ¥è¯¢é”™è¯¯ï¼Œè¯·æŸ¥çœ‹åå°æ—¥å¿—ã€‚")

    @filter.command("å…¥åœº")
    async def analyze_entry(self, event: AstrMessageEvent, uid: str):
        """æŸ¥è¯¢ç”¨æˆ·å…¥åœºè®°å½• - æ”¯æŒå¤šç§UIDæ ¼å¼"""
        # éªŒè¯å¹¶æå–UID
        valid, result = self._validate_uid(uid)
        if not valid:
            yield event.plain_result(result)
            return

        # result ç°åœ¨æ˜¯æå–åçš„çº¯æ•°å­—UID
        extracted_uid = result

        # ä½¿ç”¨ dd_page_size é…ç½®
        page_size = self.config.get("dd_page_size", self.DEFAULT_ENTRY_PAGE_SIZE)

        yield event.plain_result(f"ğŸ” æ­£åœ¨æŸ¥è¯¢ UID: {extracted_uid} çš„å…¥åœºè®°å½•...")

        try:
            # å¹¶å‘è·å–æ‰€æœ‰æ•°æ®
            tasks = [
                self._fetch_entry_data(extracted_uid, page_size=page_size),
                self._make_request(self.AICU_BILI_API_URL, {'mid': extracted_uid}),
                self._make_request(self.AICU_MARK_API_URL, {'uid': extracted_uid}),
                self._fetch_medal_data(extracted_uid),
                self._fetch_guard_data(extracted_uid)
            ]

            entry_raw, bili_raw, mark_raw, medal_raw, guard_raw = await asyncio.gather(*tasks)

            if not entry_raw:
                yield event.plain_result(f"âŒ å…¥åœºä¿¡æ¯è·å–å¤±è´¥ã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–APIæ˜¯å¦å¯ç”¨ã€‚")
                return

            entry_data = self._parse_entry(entry_raw)

            if entry_data["total"] == 0:
                yield event.plain_result(f"ğŸ” æœªæ‰¾åˆ° UID: {extracted_uid} çš„å…¥åœºè®°å½•")
                return

            profile = self._parse_profile(bili_raw, extracted_uid)
            device_name, history_names = self._parse_device(mark_raw)
            medals = self._parse_medal_data(medal_raw)
            guards = self._parse_guard_data(guard_raw)

            # ç¡®ä¿ history_names æ˜¯åˆ—è¡¨ä¸”å¯åˆ‡ç‰‡
            if not history_names:
                history_names = []
            elif not isinstance(history_names, list):
                history_names = []

            render_data = {
                "uid": extracted_uid,
                "profile": profile,
                "device_name": device_name,
                "history_names": history_names[:5],
                "medals": medals[:10],  # æœ€å¤šæ˜¾ç¤º10ä¸ªç²‰ä¸ç‰Œ
                "guards": guards[:5],   # æœ€å¤šæ˜¾ç¤º5ä¸ªå¤§èˆªæµ·
                "entry_list": entry_data["list"],
                "total_count": entry_data["total"],
                "fetched_count": len(entry_data["list"]),
                "has_more": entry_data["has_more"],
                "page_num": entry_data["page_num"] + 1,  # è½¬æ¢ä¸º1-based
                "page_size": entry_data["page_size"],
                "room_count": entry_data["stats"]["room_count"],
                "anchor_count": entry_data["stats"]["anchor_count"],
                "avg_duration": entry_data["stats"]["avg_duration"],
                "most_active_anchor": entry_data["stats"]["most_active_anchor"],
                "generate_time": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                "search_type": "å…¥åœºè®°å½•"
            }

            # ä½¿ç”¨å…¥åœºä¿¡æ¯ä¸“ç”¨æ¨¡æ¿
            img_path = await self._render_image(render_data, "template_entry.html")
            yield event.image_result(img_path)

        except Exception as e:
            logger.error(f"å…¥åœºè®°å½•æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
            yield event.plain_result(f"âŒ å…¥åœºè®°å½•æŸ¥è¯¢é”™è¯¯ï¼Œè¯·æŸ¥çœ‹åå°æ—¥å¿—ã€‚")

    @filter.command("bç«™å¸®åŠ©")
    async def show_help(self, event: AstrMessageEvent):
        """æ˜¾ç¤ºBç«™æŸ¥è¯¢æ’ä»¶å¸®åŠ©ä¿¡æ¯"""
        help_text = """
ğŸ® AICU Bç«™æŸ¥è¯¢æ’ä»¶å¸®åŠ©ä¿¡æ¯

ğŸ” å¯ç”¨å‘½ä»¤ï¼š

1ï¸âƒ£ ç”¨æˆ·è¯„è®ºæŸ¥è¯¢
ğŸ“ å‘½ä»¤ï¼š/uid <UID>
ğŸ“‹ è¯´æ˜ï¼šæŸ¥è¯¢Bç«™ç”¨æˆ·çš„è¯„è®ºè®°å½•ã€è®¾å¤‡ä¿¡æ¯å’Œæ´»è·ƒæ—¶æ®µ
ğŸ’¡ ç¤ºä¾‹ï¼š/uid 123456789

2ï¸âƒ£ å¼¹å¹•è®°å½•æŸ¥è¯¢
ğŸ“ å‘½ä»¤ï¼š/å¼¹å¹• <UID>
ğŸ“‹ è¯´æ˜ï¼šæŸ¥è¯¢ç”¨æˆ·åœ¨Bç«™è§†é¢‘ä¸­çš„å¼¹å¹•è®°å½•
ğŸ’¡ ç¤ºä¾‹ï¼š/å¼¹å¹• 123456789

3ï¸âƒ£ ç›´æ’­å¼¹å¹•æŸ¥è¯¢
ğŸ“ å‘½ä»¤ï¼š/ç›´æ’­å¼¹å¹• <UID>
ğŸ“‹ è¯´æ˜ï¼šæŸ¥è¯¢ç”¨æˆ·åœ¨Bç«™ç›´æ’­é—´çš„å¼¹å¹•è®°å½•
ğŸ’¡ ç¤ºä¾‹ï¼š/ç›´æ’­å¼¹å¹• 123456789

4ï¸âƒ£ å…¥åœºè®°å½•æŸ¥è¯¢
ğŸ“ å‘½ä»¤ï¼š/å…¥åœº <UID>
ğŸ“‹ è¯´æ˜ï¼šæŸ¥è¯¢ç”¨æˆ·çš„ç›´æ’­é—´å…¥åœºè®°å½•ã€ç²‰ä¸ç‰Œå’Œå¤§èˆªæµ·ä¿¡æ¯
ğŸ’¡ ç¤ºä¾‹ï¼š/å…¥åœº 123456789

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿åé¦ˆï¼
"""
        yield event.plain_result(help_text.strip())
